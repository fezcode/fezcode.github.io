"use strict";(self.webpackChunkfezcodex=self.webpackChunkfezcodex||[]).push([[1714],{31714(e,t,r){r.r(t),r.d(t,{default:()=>s});r(9950);var a=r(44414);function s(){return(0,a.jsxs)("div",{className:"space-y-6 font-mono text-sm leading-relaxed",children:[(0,a.jsxs)("p",{children:["A ",(0,a.jsx)("strong",{className:"text-current",children:"Crawler"})," (or bot) is an automated program that visits websites to index content for search engines (like Google) or to generate link previews for social media (like Twitter and Discord)."]}),(0,a.jsx)("div",{className:"pl-4 border-l-2 border-emerald-500 py-2 my-6 text-xs text-gray-400 italic",children:'"I visit the URL, read the meta tags, and report back what I found."'}),(0,a.jsxs)("p",{children:["Most crawlers are simple: they fetch the ",(0,a.jsx)("code",{className:"text-emerald-400",children:"index.html"})," and look at the source code. If your site relies entirely on JavaScript to render its content (CSR), the crawler sees a blank page."]}),(0,a.jsxs)("p",{children:["By using ",(0,a.jsx)("strong",{className:"text-current",children:"Static Site Generation (SSG)"}),", we ensure that every route on Fezcodex has a unique HTML file that any crawler can read, ensuring perfect SEO and rich social thumbnails."]})]})}}}]);